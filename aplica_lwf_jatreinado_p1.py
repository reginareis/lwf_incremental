# -*- coding: utf-8 -*-
"""Aplica_LwF_JaTreinado.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17v1WxglCifH0jHpCui7ZcJPRStCe5a1X
"""

from __future__ import division, print_function

#namecase = '1StanfordColab'
#namecase = '1Real_v3'
#namecase = '1Real2Pix_allshared_v2'
#namecase = '1Real2Pix_soFC_v2'
#namecase = '1Real2Wgan_allshared'
#namecase = '1Real2Wgan_soFC'
#namecase = '1AlltogetherWGAN'
#namecase = '1AlltogetherPix'
#namecase = '1StanfordBloco'
#namecase = '2ShenzhenBloco'
#namecase = '2Real_3Manaus'
#namecase = '1Stanford'
#namecase = '1Stanford2Shenzhen'
#namecase = '1Stanford_lr1e4'
#namecase = '2WganSoFC_3Manaus'
#namecase = '2WganP2PSoFC'
#namecase = '2WganSoFC_3Manaus_4SCasa'
#namecase = '2WganSoFC_3ManausSoFC'
#namecase = '2Real_3Manaus_4SCasaCycleShenzhen'								  
#namecase = '2Real_3Manaus_4SCasaCycleManaus'
#namecase = '2Real_3Manaus_4SCasaCycleAll'
#namecase = '2WganSoFC_3ManausAll_4SCasaCycleAll'
#namecase = '2WganSoFC_3ManausAll_4SCasaCycleManaus'
#namecase = '2WganSoFC_3ManausAll_4SCasaCycleShenzhen'
#namecase = '2WganSoFC_3ManausAll'
#namecase = '2Real_3Manaus'
#namecase = '1Manaus'
#namecase = '1Shenzhen'
namecase = '1SantaCasaCycleShenzhen'

pathcsv = '/home/regina.alves/results/lwf_res/SENS90/'
csvOld = '' #pathcsv + 'ResultsShenzhenSozinho.csv'
csvNew = pathcsv + 'ResultsSC_Shenzhen_Sozinho.csv'
      
taskData = "SantaCasa"
taskModel = "SantaCasa"
inputCycle = 'ShenzhenToSantaCasa'
sufixo = ""
nomeDoenca = "TB"
ilayer = -1 #qual é o id do classificador da tarefa sendo avaliada. Lembrar que =0 é o dataset genérico, primeira doença
           #está no 1. Se for a última, pode usar -1  
calcula_roc = True
save_shared = False #salvar output de 4096 dimensões após passar por camadas shared
Sens90 = True #determina que ponto de operação tem que ser com sensibilidade > 90%

histogramEqualization = False
imgwidth = 224

#modelpath = '/home/regina.alves/results/lwf_res/1StanfordColab/'
modelpath = pathcsv + namecase + '/'
results_file = modelpath + 'resultados_data' + taskData + 'caso' + namecase + '_ilayer' + str(ilayer) + sufixo + '.pkl'

#Gráfico da curva ROC
namegraf = modelpath + 'ROC_data' + taskData + 'caso' + namecase  + sufixo + '.png'

#---- Paths for already loaded data. Always have ntasks dimension, but if the task don't have the pickle
#with the loaded data =  "false"
if taskData == "Stanford":
  taskPath = "/home/regina.alves/dados_radiografias/infoStanford.pkl" #ou False se nao for task antiga
  #Information about folds - different for TB to follow Otto's partition
  infoTestFold = "/home/regina.alves/info/test_folds_stanford.pkl" #ou False se nao for task antiga
  partition_path = False #pickle com partition do Otto
  
elif taskData == "Shenzhen":
  taskPath = "/home/regina.alves/dados_radiografias/infoShenPartitionOtto.pkl"
  #Information about folds - different for TB to follow Otto's partition
  infoTestFold = False #"/home/regina.alves/info/test_folds_stanford.pkl" #ou False se nao for task antiga
  partition_path = "/home/regina.alves/info/partition.pkl" #pickle com partition do Otto

elif taskData == "Manaus":
  taskPath = False
  infoTestFold = False
  csv_path = '/home/brics/public/brics_data/Manaus/c_manaus/raw/Manaus_c_manaus_table_from_raw.csv'
  partition_path = "/home/brics/public/brics_data/Manaus/c_manaus/raw/splits.pkl"

#tarefa com dados reais da Santa Casa - carregar das pastas e ler partition em csv----------------------------
elif taskData == 'SantaCasa':
  taskPath = False
  infoTestFold = False
  #caminho de dados de TB da cycle
  if inputCycle == 'ShenzhenToSantaCasa':
      fake_path_tb = '/home/brics/public/brics_data/SantaCasa/imageamento_anonimizado_valid/fake_images/user.otto.tavares.task.SantaCasa_imageamento_anonimizado_valid.cycle_v1_tb.r1.Shenzhen_to_SantaCasa.samples/job.test_'
      fake_path_tb2 = ''
  elif inputCycle == 'ManausToSantaCasa':
    fake_path_tb = '/home/brics/public/brics_data/Manaus/c_manaus/fake_images/user.otto.tavares.Manaus.c_manaus.cycle_v1_tb.r5.Manaus_to_SantaCasa.samples/job.test_'
    fake_path_tb2 = ''
  elif inputCycle == 'AllToSantaCasa':
    fake_path_tb = '/home/brics/public/brics_data/Manaus/c_manaus/fake_images/user.otto.tavares.Manaus.c_manaus.cycle_v1_tb.r5.Manaus_to_SantaCasa.samples/job.test_'
    fake_path_tb2 = '/home/brics/public/brics_data/SantaCasa/imageamento_anonimizado_valid/fake_images/user.otto.tavares.task.SantaCasa_imageamento_anonimizado_valid.cycle_v1_tb.r1.Shenzhen_to_SantaCasa.samples/job.test_'
  path_img = '/home/brics/public/brics_data/SantaCasa/imageamento/raw/images/'
  csv_path = '/home/brics/public/brics_data/SantaCasa/imageamento/raw/user.joao.pinto_SantaCasa_imageamento_table_from_raw_splitted.csv'


nkfolds = 10
usecuda = True
Results_header = [ 'Caso',	'Sens ' + nomeDoenca + ' Val',	'Spec ' + nomeDoenca + ' Val',	'SP ' + nomeDoenca + ' Val',	'Sens ' + nomeDoenca + ' Treino',	'Spec ' + nomeDoenca + ' Treino',	'SP ' + nomeDoenca + ' Treino',	'Sens ' + nomeDoenca + ' Treino + Val',	'Spec ' + nomeDoenca + ' Treino + Val',	'SP ' + nomeDoenca + ' Treino + Val',	'Sens ' + nomeDoenca + ' Teste',	'Spec ' + nomeDoenca + ' Teste',	'SP ' + nomeDoenca + ' Teste',	'Sens ' + nomeDoenca + ' Todos',	'Spec ' + nomeDoenca + ' Todos',	'SP ' + nomeDoenca + ' Todos' ]	
# Results_header = [ 'Caso','Sens TB Val',	'Spec TB Val',	'SP TB Val',	'Sens TB Treino',	'Spec TB Treino',	'SP TB Treino',	'Sens TB Treino + Val',	'Spec TB Treino + Val',	'SP TB Treino + Val',	'Sens TB Teste',	'Spec TB Teste',	'SP TB Teste' ]


import argparse
import copy
import json
import warnings

import dataset
from loaddata_paper import *
import networks as net
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchnet as tnt
import utils as utils
from prune import SparsePruner
from torch.autograd import Variable
from tqdm import tqdm
import collections
import pickle
import numpy as np
from sklearn.model_selection import StratifiedKFold
import math
import matplotlib.pyplot as plt

import os
from ELLA import ELLA
from functions_apply_lwf import *
import sys 
import csv

#START CODE

#Declara lista do tabelao Otto
Lista_csv_tabelao = []
#Leitura do csv antigo
Lista_csv = []
if csvOld != '':
  with open( csvOld, mode='r') as csv_file:
      csv_reader = csv.DictReader(csv_file)
      for row in csv_reader:
          Lista_csv.append( row)

#Information about which partition gave the operation model (OM) for task
#always obtain len( ifoldOM ) = ntasks. Se não existir, calcula mais para frente no código.
#-------------------------------------------------------------------------
Data_csv = {}
Data_csv_tabelao = {}

iFoldOMTask = -1
jFoldOMTask = -1
iFoldOMTask, jFoldOMTask = findOperModelIJ( taskModel, modelpath, sufixo = sufixo)
print("i=" + str(iFoldOMTask))
print("j=" + str(jFoldOMTask))

#-------------------------------------------------------------------------
################################################################################################
#loading data, names, labels - Tarefas que já têm dados carregados em pickle
if( taskPath ):
    datas, labels, namesImg = Load_Data_Tasks( taskPath, True )

#-------------------------------------------------------------------------
#loading partitions - tarefas sem ser TB
Id_folds = []
if( infoTestFold ):
  print("carregou infotestfold" )
  Id_folds = Load_partition_task( infoTestFold, namesImg )   

#------ Loading Otto's partition for TB-------------------------------------
if (taskData == "Shenzhen" ):
  a_file = open(partition_path, "rb")
  partition = pickle.load(a_file)
  a_file.close()

if taskData == 'Manaus':
  datas, labels, namesImg = Load_Names_Manaus( csv_path )
  a_file = open(partition_path, "rb")
  partition = pickle.load(a_file)
  a_file.close()
################################################################################################

print("Inicio da rotina para operation point")
#Chose operation point

#Define o vetor com as especificidades discretas, de 2 em 2%. Para todos os 10 modelos, irei calcular a sensibilidade correspondente usando a funcao interpola.
nValues = 49
ndeltas = 120
specDiscrete = []   
for i in range( nValues ):
  specDiscrete.append( i*0.02 )
sensDiscrete = []

#Define ponto de operação e curva ROC para pneumo-----------------------------------------------------
#-----------------------------------------------------------------------------------------------------
deltaOp = nkfolds * [ 0 ]
if ( calcula_roc ):
  Class_Models = []
  sensDiscrete = []
  for imodel in range( nkfolds ):  
    #Carrega dados desta partition
    if imodel == iFoldOMTask:
      filename, j  = findfile( taskModel + "_Best" + sufixo, modelpath, imodel )
      modelname = modelpath + filename
    else:
      print("Name: " + taskModel + str( imodel ) )
      print(modelpath)
      filename, j  = findfile( taskModel + sufixo, modelpath,  imodel )
      modelname = modelpath + filename

    print("Modelname é " + str( modelname ))
    if ( taskData == 'Stanford' ):
      datalwf, labellwf, namelwf = Define_Data_Fold_Stanford( imodel, j, Id_folds, datas,
                                      labels, namesImg )  
    elif ( taskData == 'Shenzhen' ):
      datalwf, labellwf, namelwf = Define_Data_Fold_Partition( imodel, j, partition, datas,
                                labels, namesImg )
    
    elif taskData == 'Manaus':
      datalwf, labellwf, namelwf = Define_Data_Fold_Partition_Manaus( imodel, j, partition, datas, labels, namesImg )                                      
        
    elif( taskData == 'SantaCasa'  ):
      datalwf, labellwf, namelwf = Define_Data_Fold_SantaCasa( path_img, csv_path, fake_path_tb, fake_path_tb2, imodel, j )                         
        
    
    print("Calculando variacoes de delta para modelo " + str(imodel))
    sensAux, Class_Model, deltas = Calcula_ROC( modelname, specDiscrete,
                  datalwf, labellwf, namelwf, ndeltas, ilayer = ilayer  )

    sensDiscrete.append( sensAux )
      
    #Acrescenta resultado dos vários deltas de um modelo ao vetor com todos os modelos
    Class_Models.append( Class_Model )

    #Calcula delta de operação com maior SP para relatar resultados, caso se queira
    deltaOp[ imodel ] = Calcula_Delta_Operacao( Class_Model, deltas, Sens90 )

  
  #Plota curva ROC
  Plota_ROC( sensDiscrete, specDiscrete, namegraf, linhaoms = False )


##################################################################################################

"""# Apply a dataset to all classifiers"""

#Aplicar modelo aos dados -  estrutura separada por folds para cálculos de estatísticas
Class_Train = Modeltasks( nkfolds )
Class_Val = Modeltasks( nkfolds )
Class_Test = Modeltasks( nkfolds )
Class_TrainVal = Modeltasks( nkfolds )
Class_All = Modeltasks( nkfolds )

features_shared, output_last, labels_last, names_last = [], [], [], []
output_last_test, labels_last_test, names_last_test = [], [], []
output_last_train, labels_last_train, names_last_train = [], [], []
itask = 0 #se refere à tarefa à qual os dados pertencem

print("Aplica modelo ao dataset")
for imodel in range( nkfolds ): #models that were generated learning iModelTask, one for each iModelTask fold
  if imodel == iFoldOMTask:
    filename, j  = findfile( taskModel + "_Best" + sufixo , modelpath, imodel )
    modelname = modelpath + filename
  else:
    filename, j  = findfile( taskModel + sufixo, modelpath, imodel )
    modelname = modelpath + filename
 
  if ( taskData == 'Stanford' ):
    datalwf, labellwf, namelwf = Define_Data_Fold_Stanford( imodel, j, Id_folds, datas,
                                    labels, namesImg )  
  elif ( taskData == 'Shenzhen' ):
    datalwf, labellwf, namelwf = Define_Data_Fold_Partition( imodel, j, partition, datas,
                              labels, namesImg )
  
  elif taskData == 'Manaus':
    datalwf, labellwf, namelwf = Define_Data_Fold_Partition_Manaus( imodel, j, partition, datas, labels, namesImg )                                      
        
  elif( taskData == 'SantaCasa'  ):
    datalwf, labellwf, namelwf = Define_Data_Fold_SantaCasa( path_img, csv_path, fake_path_tb, fake_path_tb2, imodel, j )                         
        
  
  print("Classificador aos dados de teste ")
  output_all, labels_all, names_all, output_shared = eval_test( usecuda, modelname, datalwf[ 'test' ] , labellwf[ 'test' ],  
                                      namelwf[ 'test' ],  ilayer = ilayer, save_shared = save_shared )

  #Salva resultados do teste
  output_last_test.append( output_all )
  labels_last_test.append( labels_all )
  names_last_test.append( names_all )
  
  Calculate_Classifications_eval( output_all, labels_all, names_all, Class_Test.folder[ imodel ], deltaOp[ imodel ] )

  print("Classificador aos dados de validação")
  output_all, labels_all, names_all, output_shared = eval_test( usecuda, modelname, datalwf[ 'val' ] , labellwf[ 'val' ],  
                                      namelwf[ 'val' ],  ilayer = ilayer, save_shared = save_shared )
  #Salva resultados da validação
  output_last.append( output_all )
  labels_last.append( labels_all )
  names_last.append( names_all )
  #features_shared.append( output_shared )

  Calculate_Classifications_eval( output_all, labels_all, names_all, Class_Val.folder[ imodel ], deltaOp[ imodel ] )
  
  print("Classificador aos dados de treino ")
  output_all, labels_all, names_all, output_shared = eval_test( usecuda, modelname, datalwf[ 'train' ] , labellwf[ 'train' ],  
                                      namelwf[ 'train' ],  ilayer = ilayer, save_shared = save_shared )

  #Salva resultados do treino
  output_last_train.append( output_all )
  labels_last_train.append( labels_all )
  names_last_train.append( names_all )
  
  Calculate_Classifications_eval( output_all, labels_all, names_all, Class_Train.folder[ imodel ], deltaOp[ imodel ] )
  
  
  
  print("Classificador aos dados de treino + val")
  output_all, labels_all, names_all, output_shared = eval_test( usecuda, modelname, datalwf[ 'trainval' ] , labellwf[ 'trainval' ],  
                                      namelwf[ 'trainval' ],  ilayer = ilayer, save_shared = save_shared )

  Calculate_Classifications_eval( output_all, labels_all, names_all, Class_TrainVal.folder[ imodel ], deltaOp[ imodel ] )
  
  
  print("Classificador a todos os dados")
  if taskData != 'SantaCasa':
    output_all, labels_all, names_all, output_shared = eval_test( usecuda, modelname, datas,
                                                labels, namesImg,  ilayer = ilayer, save_shared = save_shared )
  else:
    output_all, labels_all, names_all, output_shared = eval_test( usecuda, modelname, datalwf['all'], labellwf['all'], namelwf['all'],  ilayer = ilayer, save_shared = save_shared )
  
  
  Calculate_Classifications_eval( output_all, labels_all, names_all, Class_All.folder[ imodel ], deltaOp[ imodel ] )
        
Create_Sets_with_VPFPVNFN_from_all_folds ( Class_Train )
Create_Sets_with_VPFPVNFN_from_all_folds ( Class_TrainVal )
Create_Sets_with_VPFPVNFN_from_all_folds ( Class_Test )
Create_Sets_with_VPFPVNFN_from_all_folds ( Class_Val )

#Salva resultados em pickle
resultados = {'Class_Train': Class_Train, 'Class_Val': Class_Val, 'Class_Test': Class_Test, 'Class_TrainVal': Class_TrainVal, 
              'Class_All': Class_All, 'output_shared': output_shared, 'output_last_val': output_last,
               'labels_last_val': labels_last, 'names_last_val': names_last, 
                'output_last_test': output_last_test, 'labels_last_test': labels_last_test, 
                'names_last_test': names_last_test, 'output_last_train': output_last_train, 'labels_last_train': labels_last_train, 
                'names_last_train': names_last_train, 'deltaOp': deltaOp }

a_file = open( results_file, "wb" )
pickle.dump( resultados, a_file )
a_file.close()

Data_csv['Caso'] = namecase + "_" + taskData

print("Resultado do Classificador aos dados de treino")
sens, spec, sp = Calculate_indexes_mean_std( Class_Train )
Data_csv['Sens ' + nomeDoenca + ' Treino'] = sens
Data_csv['Spec ' + nomeDoenca + ' Treino'] = spec
Data_csv['SP ' + nomeDoenca + ' Treino'] = sp

print("Resultado do Classificador aos dados de treino + val")
sens, spec, sp = Calculate_indexes_mean_std( Class_TrainVal )
Data_csv['Sens ' + nomeDoenca + ' Treino + Val'] = sens
Data_csv['Spec ' + nomeDoenca + ' Treino + Val'] = spec
Data_csv['SP ' + nomeDoenca + ' Treino + Val'] = sp

print("Resultado do Classificador aos dados de  val")
sens, spec, sp = Calculate_indexes_mean_std( Class_Val )
Data_csv['Sens ' + nomeDoenca + ' Val'] = sens
Data_csv['Spec ' + nomeDoenca + ' Val'] = spec
Data_csv['SP ' + nomeDoenca + ' Val'] = sp

print("Resultado do Classificador aos dados de teste")
sens, spec, sp = Calculate_indexes_mean_std( Class_Test )
Data_csv['Sens ' + nomeDoenca + ' Teste'] = sens
Data_csv['Spec ' + nomeDoenca + ' Teste'] = spec
Data_csv['SP ' + nomeDoenca + ' Teste'] = sp

print("Resultado do Classificador a todos os dados")
sens, spec, sp = Calculate_indexes_mean_std( Class_All )
Data_csv['Sens ' + nomeDoenca + ' Todos'] = sens
Data_csv['Spec ' + nomeDoenca + ' Todos'] = spec
Data_csv['SP ' + nomeDoenca + ' Todos'] = sp

Lista_csv.append( Data_csv )
with open( csvNew, 'w') as file:
    # Create a CSV dictionary writer and add the student header as field names
    writer = csv.DictWriter(file, fieldnames=Results_header)
    # Use writerows() not writerow()
    writer.writeheader()
    writer.writerows( Lista_csv )

