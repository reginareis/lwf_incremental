# -*- coding: utf-8 -*-
"""LoadDataCXR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U7C1g29oDbRe32rTcyhCUl-Cs9b59936
"""

import glob
import matplotlib.pyplot as plt
import numpy as np
import torch
import pandas as pd
from PIL import Image
import pickle
from sklearn.utils import shuffle
from sklearn.model_selection import StratifiedKFold
import os


def histogram_equalization( img_array ):

  ######################################
  # PERFORM HISTOGRAM EQUALIZATION
  ######################################

  """
  STEP 1: Normalized cumulative histogram
  """
  #flatten image array and calculate histogram via binning
  histogram_array = np.bincount(img_array.flatten(), minlength=256)

  #normalize
  num_pixels = np.sum(histogram_array)
  histogram_array = histogram_array/num_pixels

  #normalized cumulative histogram
  chistogram_array = np.cumsum(histogram_array)


  """
  STEP 2: Pixel mapping lookup table
  """
  transform_map = np.floor(255 * chistogram_array).astype(np.uint8)


  """
  STEP 3: Transformation
  """
  # flatten image array into 1D list
  img_list = list(img_array.flatten())

  # transform pixel values to equalize
  eq_img_list = [transform_map[p] for p in img_list]

  # reshape and write back into img_array
  eq_img_array = np.reshape(np.asarray(eq_img_list), img_array.shape)

  #transform to rgb
  img = Image.fromarray( eq_img_array, mode='L')
  img = img.convert('RGB')
  eq_img_array = np.asarray(img)

  return eq_img_array

def Load_Imaging( names, path, imgwidth = 224, histogramEqualization = False ):
  data, data_labels = [], []
  label = 0
  for name in names:
    myFile = path + name
    data.append( myFile )
    data_labels.append(label)
  data_labels = np.array(data_labels)
  data = np.array( data )
  names = np.array(names)
  
  return data, data_labels, names

def Load_Data( histogramEqualization, imgwidth, sizePath, file_path, 
               label, data, data_labels, img_names, onlyfake = True  ):
    
    #print("filepath load data: " + file_path)
    files = glob.glob(file_path) # your image path
    for myFile in files:
        name = str(myFile)
        name = name[ sizePath:: ]
        #print("name image: " + name )
        if ( onlyfake and name[ -10:-6 ] == 'real'):
          continue        
        img = Image.open(myFile).resize((imgwidth, imgwidth)).convert('L')
        #convert to RGB
        img = img.convert('RGB')
        #convert to NumPy array
        img_array = np.asarray(img)
        if ( histogramEqualization ):
          img_array = histogram_equalization( img_array )        
        img_array = img_array / 255
        data.append( img_array )
        data_labels.append(label)
        img_names.append(name)

def Load_Data_Batch( data_path, histogramEqualization=False, imgwidth=224 ):    
    data = []
    for myFile in data_path:    
        if '.pkl' in str(myFile):
           continue   
        img = Image.open(myFile).resize((imgwidth, imgwidth)).convert('L')
        #convert to RGB
        img = img.convert('RGB')
        #convert to NumPy array
        img_array = np.asarray(img)
        if ( histogramEqualization ):
          img_array = histogram_equalization( img_array )        
        img_array = img_array / 255
        data.append( img_array )
    data = np.array( data )
    data = data.transpose(0,3,2,1)

    return data
    
def Load_Labels_Names( sizePath, file_path, 
                       label, data, data_labels, img_names, onlyfake = True  ):
    
    #print("filepath load data: " + file_path)
    files = glob.glob(file_path) # your image path
    for myFile in files:
        name = str(myFile)
        name = name[ sizePath:: ]
        if ( onlyfake and ( 'real' in name or 'fake_B' in name ) ):
          continue      
        data_labels.append(label)
        img_names.append(name)
        path = str(myFile)
        data.append( path )

def Load_Dataset_Names( sizePathFalse, pathFalse, sizePathTrue, pathTrue, onlyfake = True ):
  #Data
  data = []
  labels = []
  names = []
  nfalse = 0
  if sizePathFalse: #tem casos em que não há dados falsos, aí o usuário passa False nesse parametro
    Load_Labels_Names( sizePathFalse, pathFalse, 0, data, labels, names, onlyfake = onlyfake  )
    print("Loaded " + str( len( labels )) + " false")
    nfalse = len( labels )
  if sizePathTrue:
    Load_Labels_Names( sizePathTrue, pathTrue, 1, data, labels, names, onlyfake = onlyfake  )
    print("Loaded " + str( len( labels ) - nfalse ) + " true")
  
  labels = np.array( labels )
  #Shuffle data
  data, labels, names = shuffle( data, labels, names, random_state=0 ) 
  data = np.array(data)
  names = np.array(names)
  print("End of load dataset")

  return data, labels, names

def Load_Data_Tasks( taskPath, islwf ):
  #Function to read data from images that have already been read in previous routine.
  #Return data array, labels and names that were saved in the structure.
  a_file = open( taskPath, "rb")
  info = pickle.load(a_file)
  a_file.close()

  label_task = np.array( info['labels'] )
  names_task = np.array( info['names'] )

  if( islwf ):
    data_task = np.array( info['data'] )
    #Transpose data to be in format expected by the CNN network
    data_task = data_task.transpose(0,3,2,1)
    # convert to torch ----------------------------------------
    data_task = torch.from_numpy( data_task ).float()
    label_task = torch.from_numpy( label_task ).long()
  print('Loaded ' + str(len( label_task ))+' from ' + taskPath)

  return data_task, label_task, names_task

def Load_Dataset( histogramEqualization, imgwidth, sizePathFalse, pathFalse, sizePathTrue, pathTrue, onlyfake = True ):
  #Data
  data = []
  labels = []
  names = []
  Load_Data( histogramEqualization, imgwidth, sizePathFalse, pathFalse, False, data, labels, names, onlyfake = onlyfake )
  print("Loaded " + str( len( labels )) + " false")
  nfalse = len( labels )
  Load_Data( histogramEqualization, imgwidth, sizePathTrue, pathTrue, True, data, labels, names, onlyfake = onlyfake )
  print("Loaded " + str( len( labels ) - nfalse ) + " true")
  data, labels = np.array( data ), np.array( labels )
  #----Shuffle data--------------------------------------------------------
  print("Next 3")
  #for i in range(10):
  #  plt.imshow( data_shuf[i], cmap='gray')
  #  plt.savefig(names_shuf[i] + str(i) + '.png')
  #Transpose data to be in format expected by the CNN network
  data = data.transpose(0,3,2,1)
  print("shape data_shuf is " + str( data.size))
  # convert to torch ----------------------------------------
  #data_shuf = torch.from_numpy( data_shuf ).float()
  #print("Next 5")
  #label_shuf = torch.from_numpy( label_shuf ).long()
  #print("Next 6")
  print("End of load dataset")
  
  #for i in range(1):
  #  plt.imshow(data[i], cmap='gray')
  #  plt.show()

  #infoDataset = { "data": data, "labels": labels, "names": names }

  return data, labels, names

def Read_pickle_others( dataPartition ):
   
  a_file = open( dataPartition, "rb")
  info = pickle.load(a_file)
  a_file.close()

  data_task = np.array( info['data'] )
  label_task = np.array( info['labels'] )
  names_task = np.array( info['names'] )

  return data_task, label_task, names_task

def Read_pickle_tasksPaths( dataPartition ):
   
  a_file = open( dataPartition, "rb")
  info = pickle.load(a_file)
  a_file.close()

  label_task = np.array( info['labels'] )
  data_task = np.array( info['data'] )
  names_task = np.array( info['names'] )

  #Transpose data to be in format expected by the CNN network
  data_task = data_task.transpose(0,3,2,1)
  # convert to torch ----------------------------------------
  data_task = torch.from_numpy( data_task ).float()
  label_task = torch.from_numpy( label_task ).long()
  print('Loaded ' + str(len(data_task))+' images' )

  return data_task, label_task, names_task

def Read_Id_Test( partitionPickle, namesImg ):    
  print('Reading previously divided folds...')
  a_file = open( partitionPickle, "rb")
  testNames = pickle.load(a_file)
  a_file.close()
  #Divide in train and test as the previously saved
  Id_test_task = []
  for iFold in range( len( testNames ) ):
    Id_test_task_fold = []
    for name in testNames[ iFold ] :
      idImg = namesImg.tolist().index( name )
      Id_test_task_fold.append( idImg )
    Id_test_task.append( Id_test_task_fold )    

  return Id_test_task

def Load_Names_Manaus( csv_path ):
    data = pd.read_csv( csv_path, delimiter = "," )
    dataPaths = np.array(list( data['image_path'] ))
    labels = np.array(list( data['target']))
    names = np.array(list( data['project_id']))

    return dataPaths, labels, names

def Load_Names_OOD_1Label( images_path, label ):
    searchpath = images_path + "*.png"
    files = glob.glob(searchpath) 
    path_size = len(images_path)
    datapaths, labels, names = [], [], []
    for myFile in files:
        print(myFile)
        datapaths.append( myFile )
        labels.append( label )
        names.append( myFile[path_size::] )
    print("Size Russia set " + str(len(names)))
    labels = np.array( labels )
    names = np.array(names)
    
    return datapaths, labels, names

def Load_Names_Imaging( csv_path, ifold, jfold ):
    data = pd.read_csv( csv_path, delimiter = "," )
    dataFilt = data[ data['test'] == ifold  ][ data['sort'] == jfold ][ data['dataset'] == 'train' ]
    namesTrain = list(dict.fromkeys( list( dataFilt['image_ID'] )))
    dataFilt = data[ data['test'] == ifold  ][ data['sort'] == jfold ][ data['dataset'] == 'val' ]
    namesVal = list(dict.fromkeys( list( dataFilt['image_ID'] )))
    dataFilt = data[ data['test'] == ifold  ][ data['sort'] == jfold ][ data['dataset'] == 'test' ]
    namesTest = list(dict.fromkeys( list( dataFilt['image_ID'] )))
    
    return namesTrain, namesVal, namesTest

def Define_Data_Fold_Fake_Alltogether_Manaus( ifold, jfold, partition, datatask, labels, namesImg,
                          fake_path_notb, fake_path_tb, loadmode = 'pix2pix' ):

  datalwf, labellwf, namelwf = {}, {}, {}

  #Dados reais
  
  datalwf['train'], labellwf['train'], namelwf['train'] = datatask[ partition[ ifold ][ jfold ][ 0 ] ], labels[partition[ ifold ][ jfold ][ 0 ] ], namesImg[partition[ ifold ][ jfold ][ 0 ] ]
  datalwf['val'], labellwf['val'], namelwf['val'] = datatask[partition[ ifold ][ jfold ][ 1 ] ], labels[partition[ ifold ][ jfold ][ 1 ] ], namesImg[partition[ ifold ][ jfold ][ 1 ] ]
  datalwf['test'], labellwf['test'], namelwf['test'] = datatask[partition[ ifold ][ jfold ][ 2 ] ], labels[partition[ ifold ][ jfold ][ 2 ] ], namesImg[partition[ ifold ][ jfold ][ 2 ] ]
  if torch.is_tensor( datalwf['train'] ):
    datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = torch.cat((datalwf['train'],datalwf['val'])), torch.cat((labellwf['train'],labellwf['val'])), np.concatenate((namelwf['train'],namelwf['val']))
    datalwf['all'], labellwf['all'], namelwf['all'] = torch.cat((datalwf['trainval'],datalwf['test'])), torch.cat((labellwf['trainval'],labellwf['test'])), np.concatenate((namelwf['trainval'],namelwf['test']))
  else:
    datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = np.concatenate((datalwf['train'],datalwf['val'])), np.concatenate((labellwf['train'],labellwf['val'])), np.concatenate((namelwf['train'],namelwf['val']))
    datalwf['all'], labellwf['all'], namelwf['all'] = np.concatenate((datalwf['trainval'],datalwf['test'])), np.concatenate((labellwf['trainval'],labellwf['test'])), np.concatenate((namelwf['trainval'],namelwf['test']))
  
  #Dados fake
    
  if loadmode == 'wgan':
    pathfalse = fake_path_notb + str(ifold) + '.sort_' + str(jfold) + "/"
    lenfalse = len( pathfalse )
    pathfalse = pathfalse + '*.png'
    pathtrue = fake_path_tb + str(ifold) + '.sort_' + str(jfold) + "/"
    lentrue = len( pathtrue )
    pathtrue = pathtrue + '*.png'
  elif loadmode == 'pix2pix':
    pathfalse = fake_path_notb + str(ifold) + '.sort_' + str(jfold) + "/TRAIN/"
    lenfalse = len( pathfalse )
    pathfalse = pathfalse + '*.png'
    pathtrue = fake_path_tb + str(ifold) + '.sort_' + str(jfold) + "/TRAIN/"
    lentrue = len( pathtrue )
    pathtrue = pathtrue + '*.png'
    
    
    #Dados fake
    datalwf['train2'], labellwf['train2'], namelwf['train2'] = Load_Dataset_Names( lenfalse, pathfalse, lentrue, pathtrue, onlyfake = True )
    print( "Tamanho data fake = " + str(len(namelwf)))

  return datalwf, labellwf, namelwf
    

def Define_Data_Fold_Fake_Alltogether( ifold, jfold, partition, datatask, labels, namesImg,
                          histogramEqualization, imgwidth, fake_path_notb, fake_path_tb, loadmode = 'wgan' ):
    
    if loadmode == 'wgan':
      pathfalse = fake_path_notb + str(ifold) + '.sort_' + str(jfold) + "/"
      lenfalse = len( pathfalse )
      pathfalse = pathfalse + '*.png'
      pathtrue = fake_path_tb + str(ifold) + '.sort_' + str(jfold) + "/"
      lentrue = len( pathtrue )
      pathtrue = pathtrue + '*.png'
    elif loadmode == 'pix2pix':
      pathfalse = fake_path_notb + str(ifold) + '.sort_' + str(jfold) + "/p2p_NTB/TRAIN/"
      lenfalse = len( pathfalse )
      pathfalse = pathfalse + '*.png'
      pathtrue = fake_path_tb + str(ifold) + '.sort_' + str(jfold) + "/p2p_TB/TRAIN/"
      lentrue = len( pathtrue )
      pathtrue = pathtrue + '*.png'
    
    datalwf, labellwf, namelwf = {}, {}, {}
    #Dados reais
    #print( len( datatask ) )
    datalwf['train'], labellwf['train'], namelwf['train'] = datatask[ partition[ ifold ][ jfold ][ 0 ] ], labels[ partition[ ifold ][ jfold ][ 0 ] ], namesImg[ partition[ ifold ][ jfold ][ 0 ] ]
    datalwf['val'], labellwf['val'], namelwf['val'] = datatask[ partition[ ifold ][ jfold ][ 1 ] ], labels[ partition[ ifold ][ jfold ][ 1 ] ], namesImg[ partition[ ifold ][ jfold ][ 1 ] ]
    datalwf['test'], labellwf['test'], namelwf['test'] = datatask[ partition[ ifold ][ jfold ][ 2 ] ], labels[ partition[ ifold ][ jfold ][ 2 ] ], namesImg[ partition[ ifold ][ jfold ][ 2 ] ]
    datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = np.concatenate((datalwf['train'],datalwf['val'])), np.concatenate((labellwf['train'],labellwf['val'])), np.concatenate((namelwf['train'],namelwf['val']))
    datalwf['all'], labellwf['all'], namelwf['all'] = np.concatenate((datalwf['trainval'],datalwf['test'])), np.concatenate((labellwf['trainval'],labellwf['test'])), np.concatenate((namelwf['trainval'],namelwf['test']))
    
    #Dados fake
    datalwf['train2'], labellwf['train2'], namelwf['train2'] = Load_Dataset_Names( lenfalse, pathfalse, lentrue, pathtrue, onlyfake = True )
    datalwf['val2'], labellwf['val2'], namelwf['val2'] = '', '', ''
    datalwf['test2'], labellwf['test2'], namelwf['test2'] = '', '', ''
    datalwf['trainval2'], labellwf['trainval2'], namelwf['trainval2'] = '', '', ''
    datalwf['all2'], labellwf['all2'], namelwf['all2'] = '', '', ''
    #datalwf['train'], labellwf['train'], namelwf['train'] = Load_Dataset( histogramEqualization, imgwidth, lenfalse, pathfalse, lentrue, pathtrue, onlyfake = True )
        
    return datalwf, labellwf, namelwf

def Define_Data_Fold_Fake_Alltogether_Only2( ifold, jfold, datalwf, labellwf, namelwf,
                                      histogramEqualization, imgwidth, 
                                       fake_path_notb, fake_path_tb, loadmode = 'wgan' ):
    
    print("Entrou nessa rotina de alltogether")
    if loadmode == 'wgan':
      pathfalse = fake_path_notb + str(ifold) + '.sort_' + str(jfold) + "/"
      lenfalse = len( pathfalse )
      pathfalse = pathfalse + '*.png'
      pathtrue = fake_path_tb + str(ifold) + '.sort_' + str(jfold) + "/"
      lentrue = len( pathtrue )
      pathtrue = pathtrue + '*.png'
    elif loadmode == 'pix2pix':
      pathfalse = fake_path_notb + str(ifold) + '.sort_' + str(jfold) + "/p2p_NTB/TRAIN/"
      lenfalse = len( pathfalse )
      pathfalse = pathfalse + '*.png'
      pathtrue = fake_path_tb + str(ifold) + '.sort_' + str(jfold) + "/p2p_TB/TRAIN/"
      lentrue = len( pathtrue )
      pathtrue = pathtrue + '*.png'
    
    #Dados fake
    datalwf['train2'], labellwf['train2'], namelwf['train2'] = Load_Dataset_Names( lenfalse, pathfalse, lentrue, pathtrue, onlyfake = True )
    datalwf['val2'], labellwf['val2'], namelwf['val2'] = '', '', ''
    datalwf['test2'], labellwf['test2'], namelwf['test2'] = '', '', ''
    datalwf['trainval2'], labellwf['trainval2'], namelwf['trainval2'] = '', '', ''
    datalwf['all2'], labellwf['all2'], namelwf['all2'] = '', '', ''
    #datalwf['train'], labellwf['train'], namelwf['train'] = Load_Dataset( histogramEqualization, imgwidth, lenfalse, pathfalse, lentrue, pathtrue, onlyfake = True )
        
    return datalwf, labellwf, namelwf
  
def Define_Data_Fold_Wgan_P2P( ifold, jfold, partition, datatask, labels, namesImg,
                          fake_path_notb, fake_path_tb, fake_path_notb_2, fake_path_tb_2 ):
    
    #dados Wgan
    pathfalse = fake_path_notb + str(ifold) + '.sort_' + str(jfold) + "/"
    lenfalse = len( pathfalse )
    pathfalse = pathfalse + '*.png'
    pathtrue = fake_path_tb + str(ifold) + '.sort_' + str(jfold) + "/"
    lentrue = len( pathtrue )
    pathtrue = pathtrue + '*.png'
    datalwf_wgan, labellwf_wgan, namelwf_wgan = Load_Dataset_Names( lenfalse, pathfalse, lentrue, pathtrue, onlyfake = True )
    print( "Tamanho data fake wgan= " + str(len(namelwf_wgan)))

    #dados p2p
    pathfalse = fake_path_notb_2 + str(ifold) + '.sort_' + str(jfold) + "/TRAIN/"
    print("Path false p2p:")
    print(pathfalse)
    lenfalse = len( pathfalse )
    pathfalse = pathfalse + '*.png'
    pathtrue = fake_path_tb_2 + str(ifold) + '.sort_' + str(jfold) + "/TRAIN/"
    print("Path true p2p:")
    print(pathtrue)
    lentrue = len( pathtrue )
    pathtrue = pathtrue + '*.png'
    datalwf_p2p, labellwf_p2p, namelwf_p2p = Load_Dataset_Names( lenfalse, pathfalse, lentrue, pathtrue, onlyfake = True )
    print( "Tamanho data fake p2p= " + str(len(namelwf_p2p)))
    
    datalwf, labellwf, namelwf = {}, {}, {}
    
    #Dados fake
    datalwf['train'], labellwf['train'], namelwf['train'] = np.concatenate((datalwf_wgan,datalwf_p2p)), np.concatenate((labellwf_wgan,labellwf_p2p)), np.concatenate((namelwf_wgan, namelwf_p2p))
    print( "Tamanho data fake 2 conjuntos = " + str(len(namelwf['train'])))
    #Dados reais
    datareal, labelreal, namereal = datatask[ partition[ ifold ][ jfold ][ 0 ] ], labels[ partition[ ifold ][ jfold ][ 0 ] ], namesImg[ partition[ ifold ][ jfold ][ 0 ] ]
    datalwf['val'], labellwf['val'], namelwf['val'] = datatask[ partition[ ifold ][ jfold ][ 1 ] ], labels[ partition[ ifold ][ jfold ][ 1 ] ], namesImg[ partition[ ifold ][ jfold ][ 1 ] ]
    datalwf['test'], labellwf['test'], namelwf['test'] = datatask[ partition[ ifold ][ jfold ][ 2 ] ], labels[ partition[ ifold ][ jfold ][ 2 ] ], namesImg[ partition[ ifold ][ jfold ][ 2 ] ]
    datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = np.concatenate((datareal,datalwf['val'])), np.concatenate((labelreal,labellwf['val'])), np.concatenate((namereal,namelwf['val']))
    datalwf['all'], labellwf['all'], namelwf['all'] = np.concatenate((datalwf['trainval'],datalwf['test'])), np.concatenate((labellwf['trainval'],labellwf['test'])), np.concatenate((namelwf['trainval'],namelwf['test']))
    
    #Variáveis dummy
    datalwf['train2'], labellwf['train2'], namelwf['train2'] = '', '', ''
    datalwf['val2'], labellwf['val2'], namelwf['val2'] = '', '', ''
    datalwf['test2'], labellwf['test2'], namelwf['test2'] = '', '', ''
    datalwf['trainval2'], labellwf['trainval2'], namelwf['trainval2'] = '', '', ''
    datalwf['all2'], labellwf['all2'], namelwf['all2'] = '', '', ''
    #datalwf['train'], labellwf['train'], namelwf['train'] = Load_Dataset( histogramEqualization, imgwidth, lenfalse, pathfalse, lentrue, pathtrue, onlyfake = True )
        
    return datalwf, labellwf, namelwf

def Define_Data_Fold_Fake( ifold, jfold, partition, datatask, labels, namesImg,
                          histogramEqualization, imgwidth, fake_path_notb, fake_path_tb, loadmode = 'wgan' ):
    
    if loadmode == 'wgan':
      pathfalse = fake_path_notb + str(ifold) + '.sort_' + str(jfold) + "/"
      lenfalse = len( pathfalse )
      pathfalse = pathfalse + '*.png'
      pathtrue = fake_path_tb + str(ifold) + '.sort_' + str(jfold) + "/"
      lentrue = len( pathtrue )
      pathtrue = pathtrue + '*.png'
    elif loadmode == 'pix2pix':
      pathfalse = fake_path_notb + str(ifold) + '.sort_' + str(jfold) + "/TRAIN/"
      lenfalse = len( pathfalse )
      pathfalse = pathfalse + '*.png'
      pathtrue = fake_path_tb + str(ifold) + '.sort_' + str(jfold) + "/TRAIN/"
      lentrue = len( pathtrue )
      pathtrue = pathtrue + '*.png'
    
    datalwf, labellwf, namelwf = {}, {}, {}
    
    #Dados fake
    datalwf['train'], labellwf['train'], namelwf['train'] = Load_Dataset_Names( lenfalse, pathfalse, lentrue, pathtrue, onlyfake = True )
    print( "Tamanho data fake = " + str(len(namelwf)))
    #Dados reais
    datareal, labelreal, namereal = datatask[ partition[ ifold ][ jfold ][ 0 ] ], labels[ partition[ ifold ][ jfold ][ 0 ] ], namesImg[ partition[ ifold ][ jfold ][ 0 ] ]
    datalwf['val'], labellwf['val'], namelwf['val'] = datatask[ partition[ ifold ][ jfold ][ 1 ] ], labels[ partition[ ifold ][ jfold ][ 1 ] ], namesImg[ partition[ ifold ][ jfold ][ 1 ] ]
    datalwf['test'], labellwf['test'], namelwf['test'] = datatask[ partition[ ifold ][ jfold ][ 2 ] ], labels[ partition[ ifold ][ jfold ][ 2 ] ], namesImg[ partition[ ifold ][ jfold ][ 2 ] ]
    datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = np.concatenate((datareal,datalwf['val'])), np.concatenate((labelreal,labellwf['val'])), np.concatenate((namereal,namelwf['val']))
    datalwf['all'], labellwf['all'], namelwf['all'] = np.concatenate((datalwf['trainval'],datalwf['test'])), np.concatenate((labellwf['trainval'],labellwf['test'])), np.concatenate((namelwf['trainval'],namelwf['test']))
    
    #Variáveis dummy
    datalwf['train2'], labellwf['train2'], namelwf['train2'] = '', '', ''
    datalwf['val2'], labellwf['val2'], namelwf['val2'] = '', '', ''
    datalwf['test2'], labellwf['test2'], namelwf['test2'] = '', '', ''
    datalwf['trainval2'], labellwf['trainval2'], namelwf['trainval2'] = '', '', ''
    datalwf['all2'], labellwf['all2'], namelwf['all2'] = '', '', ''
    #datalwf['train'], labellwf['train'], namelwf['train'] = Load_Dataset( histogramEqualization, imgwidth, lenfalse, pathfalse, lentrue, pathtrue, onlyfake = True )
        
    return datalwf, labellwf, namelwf
  
def Define_Data_Fold_SantaCasa( path_img, csv_path, fake_path_tb, fake_path_tb2, ifold, jfold ):
    
    namesTrain, namesVal, namesTest = Load_Names_Imaging( csv_path, ifold, jfold )
    datalwf, labellwf, namelwf = {}, {}, {}
    
    #Dados da santa casa
    datalwf['train'], labellwf['train'], namelwf['train'] = Load_Imaging( namesTrain, path_img )
    datalwf['val'], labellwf['val'], namelwf['val'] = Load_Imaging( namesVal, path_img )
    datalwf['test'], labellwf['test'], namelwf['test'] = Load_Imaging( namesTest, path_img )
    nfalse = len(labellwf['train'])
    print("Tamanho datalwf antes de ler primeiro set da cycle é " + str(nfalse))
    
    #Dados cycle 
    pathtrue = fake_path_tb + str(ifold) + '.sort_' + str(jfold) + "/TRAIN/"
    lentrue = len( pathtrue )
    pathtrue = pathtrue + '*.png'
    datalwf_aux1, labellwf_aux1, namelwf_aux1= Load_Dataset_Names( False, False, lentrue, pathtrue, onlyfake = True )
    ntrue1 = len(labellwf_aux1)
    print("Tamanho datalwf Manaus é " + str(ntrue1))
    
    datalwf['train'], labellwf['train'], namelwf['train'] = np.concatenate((datalwf['train'],datalwf_aux1)), np.concatenate((labellwf['train'],labellwf_aux1)), np.concatenate((namelwf['train'],namelwf_aux1))

    #If join the two sets of cycles (origin Manaus and Shenzhen), read the second set
    if fake_path_tb2 != '':
      pathtrue = fake_path_tb2 + str(ifold) + '.sort_' + str(jfold) + "/TRAIN/"
      lentrue = len( pathtrue )
      pathtrue = pathtrue + '*.png'
      datalwf_aux2, labellwf_aux2, namelwf_aux2= Load_Dataset_Names( False, False, lentrue, pathtrue, onlyfake = True )
      ntrue2 = len(labellwf_aux2)
      print("Tamanho datalwf Shenzhen é " + str(ntrue2))
      datalwf['train'], labellwf['train'], namelwf['train'] = np.concatenate((datalwf['train'],datalwf_aux2)), np.concatenate((labellwf['train'],labellwf_aux2)), np.concatenate((namelwf['train'],namelwf_aux2))
      print("Tamanho datalwf apos ler segundo set da cycle é " + str(len(labellwf['train'])))
       
    
    #Shuffle data
    datalwf['train'], labellwf['train'], namelwf['train'] = shuffle( datalwf['train'], labellwf['train'], namelwf['train'], random_state=0 )
    
    pathtrue = fake_path_tb + str(ifold) + '.sort_' + str(jfold) + "/VAL/"
    lentrue = len( pathtrue )
    pathtrue = pathtrue + '*.png'
    datalwf_aux, labellwf_aux, namelwf_aux = Load_Dataset_Names( False, False, lentrue, pathtrue, onlyfake = True )
    datalwf['val'], labellwf['val'], namelwf['val'] = np.concatenate((datalwf['val'],datalwf_aux)), np.concatenate((labellwf['val'],labellwf_aux)), np.concatenate((namelwf['val'],namelwf_aux))
    #Shuffle data
    datalwf['val'], labellwf['val'], namelwf['val'] = shuffle( datalwf['val'], labellwf['val'], namelwf['val'], random_state=0 )
    
    datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = np.concatenate((datalwf['train'],datalwf['val'])), np.concatenate((labellwf['train'],labellwf['val'])), np.concatenate((namelwf['train'],namelwf['val']))
    datalwf['all'], labellwf['all'], namelwf['all'] = np.concatenate((datalwf['trainval'],datalwf['test'])), np.concatenate((labellwf['trainval'],labellwf['test'])), np.concatenate((namelwf['trainval'],namelwf['test']))
    
    datalwf['train2'], labellwf['train2'], namelwf['train2'] = '', '', ''
    datalwf['val2'], labellwf['val2'], namelwf['val2'] = '', '', ''
    datalwf['test2'], labellwf['test2'], namelwf['test2'] = '', '', ''

    return datalwf, labellwf, namelwf

def Define_Data_Fold_Partition( ifold, jfold, partition, datatask,
                                labels, namesImg ):

  datalwf, labellwf, namelwf = {}, {}, {}

  #Dados reais
  
  datalwf['train'], labellwf['train'], namelwf['train'] = datatask[ partition[ ifold ][ jfold ][ 0 ] ], labels[ partition[ ifold ][ jfold ][ 0 ] ], namesImg[ partition[ ifold ][ jfold ][ 0 ] ]
  datalwf['val'], labellwf['val'], namelwf['val'] = datatask[ partition[ ifold ][ jfold ][ 1 ] ], labels[ partition[ ifold ][ jfold ][ 1 ] ], namesImg[ partition[ ifold ][ jfold ][ 1 ] ]
  datalwf['test'], labellwf['test'], namelwf['test'] = datatask[ partition[ ifold ][ jfold ][ 2 ] ], labels[ partition[ ifold ][ jfold ][ 2 ] ], namesImg[ partition[ ifold ][ jfold ][ 2 ] ]
  if torch.is_tensor( datalwf['train'] ):
    datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = torch.cat((datalwf['train'],datalwf['val'])), torch.cat((labellwf['train'],labellwf['val'])), np.concatenate((namelwf['train'],namelwf['val']))
    datalwf['all'], labellwf['all'], namelwf['all'] = torch.cat((datalwf['trainval'],datalwf['test'])), torch.cat((labellwf['trainval'],labellwf['test'])), np.concatenate((namelwf['trainval'],namelwf['test']))
  else:
    datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = np.concatenate((datalwf['train'],datalwf['val'])), np.concatenate((labellwf['train'],labellwf['val'])), np.concatenate((namelwf['train'],namelwf['val']))
    datalwf['all'], labellwf['all'], namelwf['all'] = np.concatenate((datalwf['trainval'],datalwf['test'])), np.concatenate((labellwf['trainval'],labellwf['test'])), np.concatenate((namelwf['trainval'],namelwf['test']))
  

  datalwf['train2'], labellwf['train2'], namelwf['train2'] = '', '', ''
  datalwf['val2'], labellwf['val2'], namelwf['val2'] = '', '', ''
  datalwf['test2'], labellwf['test2'], namelwf['test2'] = '', '', ''
  datalwf['trainval2'], labellwf['trainval2'], namelwf['trainval2'] = '', '', ''
  datalwf['all2'], labellwf['all2'], namelwf['all2'] = '', '', ''
    
  return datalwf, labellwf, namelwf

def Define_Data_Fold_Russia( datatask, labels, namesImg ):

  datalwf, labellwf, namelwf = {}, {}, {}

  #Dados reais
  
  datalwf['train'], labellwf['train'], namelwf['train'] = datatask, labels, namesImg
  datalwf['val'], labellwf['val'], namelwf['val'] = datatask, labels, namesImg
  datalwf['test'], labellwf['test'], namelwf['test'] = datatask, labels, namesImg
  datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = datatask, labels, namesImg
  datalwf['all'], labellwf['all'], namelwf['all'] = datatask, labels, namesImg

  datalwf['train2'], labellwf['train2'], namelwf['train2'] = '', '', ''
  datalwf['val2'], labellwf['val2'], namelwf['val2'] = '', '', ''
  datalwf['test2'], labellwf['test2'], namelwf['test2'] = '', '', ''
  datalwf['trainval2'], labellwf['trainval2'], namelwf['trainval2'] = '', '', ''
  datalwf['all2'], labellwf['all2'], namelwf['all2'] = '', '', ''
    
  return datalwf, labellwf, namelwf

def Define_Data_Fold_Partition_Manaus( ifold, jfold, partition, datatask,
                                labels, namesImg ):
  print("entrou em partition")
  print(str(len(datatask)))
  datalwf, labellwf, namelwf = {}, {}, {}

  #Dados reais
  
  datalwf['train'], labellwf['train'], namelwf['train'] = datatask[ partition[ ifold ][ jfold ][ 0 ] ], labels[partition[ ifold ][ jfold ][ 0 ] ], namesImg[partition[ ifold ][ jfold ][ 0 ] ]
  datalwf['val'], labellwf['val'], namelwf['val'] = datatask[partition[ ifold ][ jfold ][ 1 ] ], labels[partition[ ifold ][ jfold ][ 1 ] ], namesImg[partition[ ifold ][ jfold ][ 1 ] ]
  datalwf['test'], labellwf['test'], namelwf['test'] = datatask[partition[ ifold ][ jfold ][ 2 ] ], labels[partition[ ifold ][ jfold ][ 2 ] ], namesImg[partition[ ifold ][ jfold ][ 2 ] ]
  if torch.is_tensor( datalwf['train'] ):
    datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = torch.cat((datalwf['train'],datalwf['val'])), torch.cat((labellwf['train'],labellwf['val'])), np.concatenate((namelwf['train'],namelwf['val']))
    datalwf['all'], labellwf['all'], namelwf['all'] = torch.cat((datalwf['trainval'],datalwf['test'])), torch.cat((labellwf['trainval'],labellwf['test'])), np.concatenate((namelwf['trainval'],namelwf['test']))
  else:
    datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = np.concatenate((datalwf['train'],datalwf['val'])), np.concatenate((labellwf['train'],labellwf['val'])), np.concatenate((namelwf['train'],namelwf['val']))
    datalwf['all'], labellwf['all'], namelwf['all'] = np.concatenate((datalwf['trainval'],datalwf['test'])), np.concatenate((labellwf['trainval'],labellwf['test'])), np.concatenate((namelwf['trainval'],namelwf['test']))
  

  datalwf['train2'], labellwf['train2'], namelwf['train2'] = '', '', ''
  datalwf['val2'], labellwf['val2'], namelwf['val2'] = '', '', ''
  datalwf['test2'], labellwf['test2'], namelwf['test2'] = '', '', ''
  datalwf['trainval2'], labellwf['trainval2'], namelwf['trainval2'] = '', '', ''
  datalwf['all2'], labellwf['all2'], namelwf['all2'] = '', '', ''
    
  return datalwf, labellwf, namelwf

def Create_train( Id_folds, itest, ivalidation ):
  #Create train joining the kfolds that are not in test nor validation
  # Id_folds - folds in which data was divided. Id_fold[ntasks][nkfolds][n elements per fold]
  # itest - fold which is being used as test, so won't be part of the train
  # ivalidation - fold which is being used as validation, so won't be part of the train

  nkfolds = len( Id_folds )
  Id_train = []
  for ikf in range( nkfolds ):
    if ( ikf != itest and ikf != ivalidation ):
      for iimg in range( len( Id_folds[ ikf ] ) ):
        Id_train.append( Id_folds[ ikf ][ iimg ] )

  return Id_train

def Define_Data_Fold_Others(  ifold, jfold, datasets, labels, namesImg ):
  nkfolds = len(labels)
  datalwf, labellwf, namelwf = {}, {}, {}

  #create train joining folds  
  primeiro = True
  for i in range(nkfolds):
    if i== ifold or i == jfold:
      continue
    if( primeiro ):
      datalwf['train'] = datasets[i]
      namelwf['train'] = namesImg[i]
      labellwf['train'] = labels[i]
      primeiro = False
    else:
      datalwf['train'] = np.concatenate( (datalwf['train'], datasets[i]) )
      namelwf['train'] = np.concatenate( (namelwf['train'], namesImg[i]) )
      labellwf['train'] = torch.cat( (labellwf['train'], labels[i]) )
  
  datalwf['test'], labellwf['test'], namelwf['test'] = datasets[ ifold ], labels[ ifold ], namesImg[ ifold ]
  datalwf['val'], labellwf['val'], namelwf['val'] = datasets[ jfold ], labels[ jfold ], namesImg[ jfold ]
  datalwf['trainval'] = np.concatenate( (datalwf['train'], datalwf['val']) )
  namelwf['trainval'] = np.concatenate( (namelwf['train'], namelwf['val']) )
  labellwf['trainval'] = torch.cat( (labellwf['train'], labellwf['val']) )
  datalwf['all'] = np.concatenate( (datalwf['trainval'], datalwf['test']) )
  namelwf['all'] = np.concatenate( (namelwf['trainval'], namelwf['test']) )
  labellwf['all'] = torch.cat( (labellwf['trainval'], labellwf['test']) )

  datalwf['train2'], labellwf['train2'], namelwf['train2'] = '', '', ''
  datalwf['val2'], labellwf['val2'], namelwf['val2'] = '', '', ''
  datalwf['test2'], labellwf['test2'], namelwf['test2'] = '', '', ''
  datalwf['trainval2'], labellwf['trainval2'], namelwf['trainval2'] = '', '', ''
  #datalwf['all2'], labellwf['all2'], namelwf['all2'] = '', '', ''


  return datalwf, labellwf, namelwf


def Define_Data_Fold_Stanford( ifold, jfold, Id_folds, data, labels, namesImg ):
  datalwf, labellwf, namelwf = {}, {}, {}
 
  Id_tr = Create_train( Id_folds, ifold, jfold ) #join all other folds in the same group
  Id_test = Id_folds[ ifold ]
  Id_val = Id_folds[ jfold ]
  Id_trval = np.concatenate( ( Id_tr, Id_val ) )

  datalwf['test'], labellwf['test'], namelwf['test'] = data[ Id_test ], labels[ Id_test ], namesImg[ Id_test ]
  datalwf['val'], labellwf['val'], namelwf['val'] = data[ Id_val ], labels[ Id_val ], namesImg[ Id_val ]
  datalwf['train'], labellwf['train'], namelwf['train'] = data[ Id_tr ], labels[ Id_tr ], namesImg[ Id_tr ]
  datalwf['trainval'], labellwf['trainval'], namelwf['trainval'] = data[ Id_trval ], labels[ Id_trval ], namesImg[ Id_trval ] 
  #datalwf['all'], labellwf['all'], namelwf['all'] = data, labels, namesImg 

  datalwf['train2'], labellwf['train2'], namelwf['train2'] = '', '', ''
  datalwf['val2'], labellwf['val2'], namelwf['val2'] = '', '', ''
  datalwf['test2'], labellwf['test2'], namelwf['test2'] = '', '', ''
  datalwf['trainval2'], labellwf['trainval2'], namelwf['trainval2'] = '', '', ''
  #datalwf['all2'], labellwf['all2'], namelwf['all2'] = '', '', ''


  return datalwf, labellwf, namelwf


#Functions to find files
def findfilebest( lastTaskName, load_path ):
    searchpath = load_path + "*.pt"
    files = glob.glob(searchpath) 
    for myFile in files:
        print ("filename " + str(myFile))
        if lastTaskName in myFile and ('Best' in myFile or 'best' in myFile):
            return myFile

def findfile(name, path, i ):
    # print( "path: " + path )
    # print("name: " + name )
    
    for dirpath, dirname, filenames in os.walk(path):
      for file in filenames:
        # print( "file nao escolhido " + str(file))
        # print( file[-9:-8] )
        if name in file and '.pt' in file and int( file[-9:-8] ) == i:
          # print( file )
          # print( file[-9:-8] )
          #i = int( file[-9:-8] )
          j = int( file[-4:-3] )  
          return file, j
    #se nao achar, retorna vazio
    return '', ''

def findOperModelIJ(taskName, path, sufixo = ''):
  #function to find file with operation model for lwf
    i, j = -1, -1
    for dirpath, dirname, filenames in os.walk(path):
      for file in filenames:
        if ("Best" + sufixo in file or "best" + sufixo in file) and ".pt" in file:
          i = int( file[-9:-8] )
          j = int( file[-4:-3] )          
    return i, j


  #function to find file with operation model for ella
    i = -1 
    for dirpath, dirname, filenames in os.walk(path):
      for file in filenames:
        if taskName + "_best" in file and ".pkl" in file:
          i = int( file[-5:-4] )          
    return i