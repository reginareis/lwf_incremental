# -*- coding: utf-8 -*-
"""Aplica_LwF_JaTreinado.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17v1WxglCifH0jHpCui7ZcJPRStCe5a1X
"""

from __future__ import division, print_function
from loaddata_paper import *
import utils as utils
import pickle
import numpy as np
import os
from functions_apply_lwf import *

userparameters = {}
userparameters['modelpath'] = '/home/regina.alves/results/lwf_res/SENS90/2Real_3Manaus_4SCasaCycleAll/'
userparameters['taskData'] = 'SantaCasa'
userparameters['inputCycle'] = 'AllToSantaCasa'
userparameters['ilayer'] = -1 #classifier id of the task being evaluated. =0 is the Imagenet dataset, first disease
                              #is at 1. If it is the last one, you can use -1
userparameters['nkfolds'] = 10

def Choose_Best_Models( userparameters):
  modelpath = userparameters['namecase']
  taskData = userparameters['taskData']
  inputCycle = userparameters['inputCycle']
  ilayer = userparameters['ilayer']
  nkfolds = userparameters['nkfolds']
  usecuda = True 

  #---- Paths for already loaded data. Always have ntasks dimension, but if the task don't have the pickle
  #with the loaded data =  "false"
  if taskData == "Stanford":
    dataPartition = "/home/regina.alves/dados_radiografias/infoStanford.pkl"
    partitionPickle = "/home/regina.alves/info/test_folds_stanford.pkl" 
  elif taskData == "Shenzhen":
    taskPath = "/home/regina.alves/dados_radiografias/infoShenPartitionOtto.pkl"
    #Information about folds - different for TB to follow Otto's partition
    partition_path = "/home/regina.alves/info/partition.pkl" #pickle com partition do Otto

  elif taskData == "Manaus":
    csv_path = '/home/brics/public/brics_data/Manaus/c_manaus/raw/Manaus_c_manaus_table_from_raw.csv'
    partition_path = "/home/brics/public/brics_data/Manaus/c_manaus/raw/splits.pkl"
  #task with real data from Santa Casa - load from folders and read partition in csv---------------------------
  elif taskData == 'SantaCasa':
    # data path for TB fake data generated by cycle-gan
    if inputCycle == 'ShenzhenToSantaCasa':
        fake_path_tb = '/home/brics/public/brics_data/SantaCasa/imageamento_anonimizado_valid/fake_images/user.otto.tavares.task.SantaCasa_imageamento_anonimizado_valid.cycle_v1_tb.r1.Shenzhen_to_SantaCasa.samples/job.test_'
        fake_path_tb2 = ''
    elif inputCycle == 'ManausToSantaCasa':
      fake_path_tb = '/home/brics/public/brics_data/Manaus/c_manaus/fake_images/user.otto.tavares.Manaus.c_manaus.cycle_v1_tb.r5.Manaus_to_SantaCasa.samples/job.test_'
      fake_path_tb2 = ''
    elif inputCycle == 'AllToSantaCasa':
      fake_path_tb = '/home/brics/public/brics_data/Manaus/c_manaus/fake_images/user.otto.tavares.Manaus.c_manaus.cycle_v1_tb.r5.Manaus_to_SantaCasa.samples/job.test_'
      fake_path_tb2 = '/home/brics/public/brics_data/SantaCasa/imageamento_anonimizado_valid/fake_images/user.otto.tavares.task.SantaCasa_imageamento_anonimizado_valid.cycle_v1_tb.r1.Shenzhen_to_SantaCasa.samples/job.test_'
    path_img = '/home/brics/public/brics_data/SantaCasa/imageamento/raw/images/'
    csv_path = '/home/brics/public/brics_data/SantaCasa/imageamento/raw/user.joao.pinto_SantaCasa_imageamento_table_from_raw_splitted.csv'

  #START CODE

  #-------------------------------------------------------------------------
  ################################################################################################
  #loading data, names, labels - Tarefas que já têm dados carregados em pickle
  if (taskData == "Stanford" ):
    datataskaux, labelsaux, namesImg = Read_pickle_tasksPaths( dataPartition )
    datas = datataskaux.numpy() #.transpose(0,3,2,1) )
    labels = labelsaux.numpy() 
    Id_folds = np.array( Read_Id_Test( partitionPickle, namesImg ) )
    print("Loaded " + str(len(labels)) + " real images from other task")

  #------ Loading Otto's partition for TB-------------------------------------
  elif (taskData == "Shenzhen" ):
    datas, labels, namesImg = Load_Data_Tasks( taskPath, True )
    partition = Load_Partition_Otto( partition_path )

  elif taskData == "Manaus":
    datas, labels, namesImg = Load_Names_Manaus( csv_path )
    a_file = open(partition_path, "rb")
    partition = pickle.load(a_file)
    a_file.close()

  elif taskData == 'SantaCasa':
    datalwf, labellwf, namelwf = Define_Data_Fold_SantaCasa( path_img, csv_path, fake_path_tb, fake_path_tb2, 0, 0 ) 
    datas, labels, namesImg = datalwf['all'], labellwf['all'], namelwf['all']

  ################################################################################################

  jbests = []
  for ifold in range( nkfolds ):  
    Class_TrainVal = Modeltasks( nkfolds )
    Class_All = Modeltasks( nkfolds )
    sp_array = []
    sp_all_array = []
    ori_modelnames = []
    for jfold in range( nkfolds ):
      if( ( jfold == ifold and taskData == 'Stanford') or ( jfold == nkfolds - 1 and taskData != 'Stanford' )   ): #can't use the same fold for test and validation
        sp_array.append( 0.0 )
        sp_all_array.append( 0.0 )
        continue
      filename, j  = findfile( str(ifold) + "_val" + str(jfold), modelpath,  ifold )
      
      if filename == '':
        print("No file found with ifold = " + str(ifold) + " and jfold = " + str(jfold) + " . Skipping these indexes")
        sp_array.append( 0.0 )
        sp_all_array.append( 0.0 )
        continue

      modelfile = modelpath + filename
      ori_modelnames.append( modelfile )
    
      print("Filename is " + str( filename ))
      if ( taskData == 'Stanford' ):
        datalwf, labellwf, namelwf = Define_Data_Fold_Stanford( ifold, jfold, Id_folds, datas,
                                        labels, namesImg )  
      elif ( taskData == 'Shenzhen'):
        datalwf, labellwf, namelwf = Define_Data_Fold_Partition( ifold, jfold, partition, datas,
                                  labels, namesImg )
        
      elif taskData == 'Manaus':
        datalwf, labellwf, namelwf = Define_Data_Fold_Partition_Manaus( ifold, jfold, partition, datas, labels, namesImg )                                      
      
      elif( taskData == 'SantaCasa'  ):
        datalwf, labellwf, namelwf = Define_Data_Fold_SantaCasa( path_img, csv_path, fake_path_tb, fake_path_tb2, ifold, jfold )                         
          
    
      print("Classifying data from train + val folders")
      output_all, labels_all, names_all, output_shared = eval_test( usecuda, modelfile, datalwf[ 'trainval' ] , labellwf[ 'trainval' ],  
                                          namelwf[ 'trainval' ],  ilayer = ilayer )

      Calculate_Classifications_eval( output_all, labels_all, names_all, Class_TrainVal.folder[ jfold ], 0.0 )
      sp_array.append( Class_TrainVal.folder[ jfold ].sp )

      print("Classifying all data")
      output_all, labels_all, names_all, output_shared = eval_test( usecuda, modelfile, datas , labels,  
                                        namesImg,  ilayer = ilayer )

      Calculate_Classifications_eval( output_all, labels_all, names_all, Class_All.folder[ jfold ], 0.0 )
      sp_all_array.append( Class_All.folder[ jfold ].sp )
    
    #Choose which of the models associated to ifold has the highest SP index in the training + val data
    jbest = sp_array.index(max(sp_array))
    jbests.append( jbest )
    print("Best model for fold " + str(ifold) + " is with jfold = " + str(jbest) + ", with sp = " + str(max(sp_array)))
    print("The sp index applied to all data is " + str(sp_all_array[jbest]))
    #Change file name associated to the best model
    ori_file = ori_modelnames[ jbest ]
    print("Original file: " + ori_file)
    mod_file = modelpath + taskData + "_test" + str(ifold) + "_val" + str(jbest)
    os.rename( ori_file, mod_file + '.pt' )
    os.rename( ori_file + '.json', mod_file + '.json' )
    os.rename( ori_file + '_epochs.png', mod_file + '_epochs.png' )

  print("Find the best model applied to all data to define the operation model that will learn next task")

  Class_All = Modeltasks( nkfolds )
  sp_array = []
  for ifold in range( nkfolds ):
    jfold =  jbests[ifold] 
    modelfile = modelpath + taskData + "_test" + str(ifold) + "_val" + str(jfold) + ".pt"
    print("Classifying all data")
    
    output_all, labels_all, names_all, output_shared = eval_test( usecuda, modelfile, datas , labels,  
                                        namesImg,  ilayer = ilayer )

    Calculate_Classifications_eval( datalwf['all'], labellwf['all'], namelwf['all'], Class_All.folder[ ifold ], 0.0 )
    sp_array.append( Class_All.folder[ ifold ].sp )

  print("Choose which of the 10 models has the highest SP index in all data")
  ibest = sp_array.index(max(sp_array))
  print("Best model to be defined as operation model is " + str(ibest) + ", with sp = " + str(max(sp_array)))
  #Change file name associated to the best model
  ori_file = modelpath + taskData + "_test" + str(ibest) + "_val" + str(jbests[ibest])
  mod_file = modelpath + taskData + "_best" + str(ibest) + "_val" + str(jbests[ibest])
  os.rename( ori_file + '.pt', mod_file + '.pt' )
  os.rename( ori_file + '.json', mod_file + '.json' )
  os.rename( ori_file + '_epochs.png', mod_file + '_epochs.png' )